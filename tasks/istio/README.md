# Istio

### Getting started - https://istio.io/latest/docs/setup/getting-started/
Download istio - https://github.com/istio/istio/releases
```
# Extract zip and add bin to PATH
# For this installation, we use the demo configuration profile
./bin/istioctl install --set profile=demo -y
# Add a namespace label to instruct Istio to automatically inject Envoy sidecar proxies when you deploy your application later
kubectl label namespace default istio-injection=enabled
# Deploy the sample application
kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml
# Open the application to outside traffic
kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml
# Get Ingress gateway external ip
kubectl get svc -n istio-system
# curl
curl http://ingress-gateway-LB-ip/productpage
```

### Istio release setup - https://istio.io/latest/docs/setup/getting-started/#download
```bash
curl -L https://git.io/getLatestIstio | ISTIO_VERSION=1.3.3 sh - && \
cd istio-1.3.3 && \
export PATH=$PWD/bin:$PATH && \
istioctl verify-install
```

# Istio-init
```bash
kubectl create namespace istio-system
helm template istio-init install/kubernetes/helm/istio-init --namespace istio-system | kubectl apply -f -
```

# Create a secret for Kiali
```yaml
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: kiali
  namespace: $(echo -n istio-system)
  labels:
    app: kiali
type: Opaque
data:
  username: $(echo -n admin | base64)
  passphrase: $(echo -n pass | base64)
EOF
```

# Istio with sds/grafana/kiali
```bash
helm template istio install/kubernetes/helm/istio \
       --namespace istio-system \
       --set gateways.istio-ingressgateway.sds.enabled=true \
       --set global.k8sIngress.enabled=true \
       --set global.k8sIngress.enableHttps=true \
       --set global.k8sIngress.gatewayName=ingressgateway \
       --set grafana.enabled=True \
       --set kiali.enabled=True | kubectl apply -f -
```

# modify the tls section of gateway/istio-autogenerated-k8s-ingress to sds
```bash
kubectl -n istio-system \
  patch gateway istio-autogenerated-k8s-ingress --type=json \
  -p='[{"op": "replace", "path": "/spec/servers/1/tls", "value": {"credentialName": "ingress-cert", "mode": "SIMPLE", "privateKey": "sds", "serverCertificate": "sds"}}]'
```

# Enable istio injection to default namespace
```bash
kubectl label ns default istio-injection=enabled
```

# helloworld deployment, service and virtualservice
```yaml
echo INGRESS_DOMAIN: && \
read INGRESS_DOMAIN && \
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Service
metadata:
  name: helloworld
  labels:
    app: helloworld
spec:
  ports:
  - port: 5000
    name: http
  selector:
    app: helloworld
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: helloworld
spec:
  selector:
    matchLabels:
      app: helloworld
  template:
    metadata:
      labels:
        app: helloworld
    spec:
      containers:
      - name: helloworld
        image: istio/examples-helloworld-v1
        resources:
          requests:
            cpu: "100m"
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 5000
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: helloworld-vs
spec:
  hosts:
  - $INGRESS_DOMAIN
  gateways:
  - istio-system/istio-autogenerated-k8s-ingress
  http:
  - match:
    - uri:
        prefix: /hello
    route:
    - destination:
        host: helloworld
        port:
          number: 5000
EOF
```

# Make sure DNS A record is set for INGRESS_DOMAIN resolving Load Balancer public ip.
* [IMPORTANT] If you are on bare metal setup, A DNS A record resolving a Haproxy host public ip address is a MUST because metallb load balancer ip is a priviate ip which is only accessible within K8s container network.  We will need to deploy a worker node to accessing metallb ip as well as serving HTTP/HTTPS requests at a public ip address, that's Haproxy comes in as a proxy service for external-internal routing.
* https://github.com/henryliu18/kubernetes-poc/tree/master/tasks/Haproxy-build-for-metallb

# Now you should be able to access helloworld application via HTTP
```curl http://$INGRESS_DOMAIN/hello```

# Staging ClusterIssuer
```yaml
echo ISSUER_EMAIL: && \
read ISSUER_EMAIL && \
cat <<EOF | kubectl apply -f -
apiVersion: cert-manager.io/v1alpha2
kind: ClusterIssuer
metadata:
  name: letsencrypt-staging
spec:
  acme:
    # You must replace this email address with your own.
    # Let's Encrypt will use this to contact you about expiring
    # certificates, and issues related to your account.
    email: ${ISSUER_EMAIL}
    server: https://acme-staging-v02.api.letsencrypt.org/directory
    privateKeySecretRef:
      # Secret resource used to store the account's private key.
      name: ingress-cert
    # Add a single challenge solver, HTTP01 using nginx
    solvers:
    - http01:
        ingress:
          class: istio
EOF
```

# Staging Certificate
```yaml
echo INGRESS_DOMAIN: && \
read INGRESS_DOMAIN && \
cat <<EOF | kubectl apply -f -
apiVersion: cert-manager.io/v1alpha2
kind: Certificate
metadata:
  name: ingress-cert
  namespace: istio-system
spec:
  secretName: ingress-cert
  issuerRef:
    name: letsencrypt-staging
    kind: ClusterIssuer
  commonName: ${INGRESS_DOMAIN}
  dnsNames:
  - ${INGRESS_DOMAIN}
EOF
```

# At this point the service should become available over HTTPS as well

```curl --insecure https://$INGRESS_DOMAIN/hello```

# [IMPORTANT] If you are getting below errors, delete istio-ingressgateway POD to make it restarting should work this around.
* curl: (35) Encountered end of file
* curl: (7) Failed connect to hello.istio.io:443; Connection refused

# Prod ClusterIssuer
```yaml
echo ISSUER_EMAIL: && \
read ISSUER_EMAIL && \
cat <<EOF | kubectl create -f -
apiVersion: cert-manager.io/v1alpha2
kind: ClusterIssuer
metadata:
  name: letsencrypt
spec:
  acme:
    # The ACME server URL
    server: https://acme-v02.api.letsencrypt.org/directory
    # Email address used for ACME registration
    email: ${ISSUER_EMAIL}
    # Name of a secret used to store the ACME account private key
    privateKeySecretRef:
      name: ingress-cert
    # Enable the HTTP-01 challenge provider
    solvers:
    - http01:
        ingress:
          class: istio
EOF
```

# Prod Certificate
```yaml
echo INGRESS_DOMAIN: && \
read INGRESS_DOMAIN && \
cat <<EOF | kubectl apply -f -
apiVersion: cert-manager.io/v1alpha2
kind: Certificate
metadata:
  name: ingress-cert
  namespace: istio-system
spec:
  secretName: ingress-cert
  issuerRef:
    name: letsencrypt
    kind: ClusterIssuer
  commonName: ${INGRESS_DOMAIN}
  dnsNames:
  - ${INGRESS_DOMAIN}
EOF
```

# Now delete the secret to force cert-manager to request a new certificate from the production issuer
```kubectl delete secret -n istio-system ingress-cert```

# watch that cert for a successful issuance
```watch -n1 kubectl describe cert ingress-cert -n istio-system```

# [IMPORTANT] HTTPS with legit certifiate should work, if not, just delete istio-ingressgateway pod :)
```curl https://$INGRESS_DOMAIN/hello```

# Deploy a Tomcat deployment, service and virtualservice
```yaml
echo TOM_INGRESS_DOMAIN: && \
read TOM_INGRESS_DOMAIN && \
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: tomcat
  name: tomcat-demo
spec:
  replicas: 2
  selector:
    matchLabels:
      app: tomcat
  template:
    metadata:
      labels:
        app: tomcat
    spec:
      containers:
      - image: tomcat:alpine
        name: tomcat
        ports:
        - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: tomcat-service
  labels:
    app: tomcat
spec:
  ports:
  - port: 8080
    name: http
    protocol: TCP
    targetPort: 8080
  selector:
    app: tomcat
  type: ClusterIP
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: tomcat-vs
spec:
  hosts:
  - $TOM_INGRESS_DOMAIN
  gateways:
  - istio-system/istio-autogenerated-k8s-ingress
  http:
  - match:
    - uri:
        prefix: /
    route:
    - destination:
        host: tomcat-service
        port:
          number: 8080
EOF
```
# Make sure $TOM_INGRESS_DOMAIN is resolved to Load Balancer ip address
```curl http://$TOM_INGRESS_DOMAIN/```

# Kiali should be exposed at ClusterIP:20001
```kubectl get service kiali -n istio-system```

# Create virtualservice for ingress control Kiali so we can access Kiali console through Haproxy -> Istio ingressgateway
```yaml
echo KIALI_INGRESS_DOMAIN: && \
read KIALI_INGRESS_DOMAIN && \
cat <<EOF | kubectl apply -f -
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: kiali-vs
  namespace: istio-system
spec:
  hosts:
  - $KIALI_INGRESS_DOMAIN
  gateways:
  - istio-system/istio-autogenerated-k8s-ingress
  http:
  - match:
    - uri:
        prefix: /
    route:
    - destination:
        host: kiali
        port:
          number: 20001
EOF
```
* Make sure $KIALI_INGRESS_DOMAIN pointing to Haproxy public ip
```curl http://$KIALI_INGRESS_DOMAIN/kiali```

# Grafana should be exposed at ClusterIP:3000
```kubectl get service grafana -n istio-system```

# Create virtualservice for ingress control Grafana so we can access Grafana console through Haproxy -> Istio ingressgateway
```yaml
echo GRAFANA_INGRESS_DOMAIN: && \
read GRAFANA_INGRESS_DOMAIN && \
cat <<EOF | kubectl apply -f -
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: grafana-vs
  namespace: istio-system
spec:
  hosts:
  - $GRAFANA_INGRESS_DOMAIN
  gateways:
  - istio-system/istio-autogenerated-k8s-ingress
  http:
  - match:
    - uri:
        prefix: /
    route:
    - destination:
        host: grafana
        port:
          number: 3000
EOF
```
* Make sure $GRAFANA_INGRESS_DOMAIN pointing to Haproxy public ip
```curl http://$GRAFANA_INGRESS_DOMAIN/```

# Cleanup
```bash
kubectl delete vs/tomcat-vs
kubectl delete svc/tomcat-service
kubectl delete deployment/tomcat-demo

kubectl delete vs/helloworld-vs
kubectl delete svc/helloworld
kubectl delete deployment/helloworld

kubectl delete vs/grafana-vs -n istio-system
kubectl delete vs/kiali-vs -n istio-system

kubectl label ns default istio-injection-

kubectl delete Secret/kiali -n istio-system

cd istio-*
echo ISSUER_EMAIL: && \
read ISSUER_EMAIL && \
helm template istio install/kubernetes/helm/istio \
       --namespace istio-system \
       --set gateways.istio-ingressgateway.sds.enabled=true \
       --set global.k8sIngress.enabled=true \
       --set global.k8sIngress.enableHttps=true \
       --set global.k8sIngress.gatewayName=ingressgateway \
       --set certmanager.enabled=true \
       --set certmanager.email=$ISSUER_EMAIL \
       --set grafana.enabled=True \
       --set kiali.enabled=True | kubectl delete -f -

helm template istio-init install/kubernetes/helm/istio-init --namespace istio-system | kubectl delete -f -
for i in install/kubernetes/helm/istio-init/files/crd*yaml; do kubectl delete -f $i; done
kubectl delete namespace istio-system
```
